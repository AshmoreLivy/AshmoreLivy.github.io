---
layout:     post
title:      数据科学导论
subtitle:   数据科学导论复习
date:       2021-05-16
author:     Ashmore
header-img: img/post-web.jpg
catalog: true
tags:
    - 学习资料
    - 机器学习
---
# 数据科学概述

1. 机器学习

- 机器学习是一门人工智能的科学，该领域的主要研
  究对象是如何在**经验学习**中**改善具体算法**的性能。
- 机器学习是对能通过**经验**自动**改进计算机算法**的研
  究。
  - 有监督学习：基于输入数据及目标值建立模型
  - 无监督学习：无监督学习不指定目标值或预先无法知道目标值

2. 深度学习解决的核心问题之一就是自动地将简单的特征组合成更加复杂的特征，并利用这些组合特征解决问题，深度学习是机器学习的一个分支。

## 数据挖掘算法概述

- 分类
- 回归
  - 一元线性回归
  - 多元线性回归
  - SVM支持向量机
  - KNN *近邻*
  - 决策树
  - 朴素贝叶斯
- 聚类
  - K-Means *K均值*
  - 层次聚类
  - 谱聚类
  - DBSCAN（基于密度）
- 集成算法
  - Bagging
  - Boosting
  - Stacking
- 模型评价
  - 分类模型：混淆矩阵、正确率、召回率
  - 回归模型：平方绝对差、均方误差、决定系数
  - 聚类模型：内部指标、外部指标、轮廓系数

# 数据预处理

- 描述性数据汇总
  - 分布式度量
  - 代数度量
  - 整体度量
  - 度量中心趋势
    - 经验公式计算众数mean−mode=3*(mean − median)
    - 方差和标准差(standard deviation)
    - 协方差
- 缺失值处理
  - 均值填补
    - 连续性-平均数
    - 离散型-众数
  - 随机填补
    - 贝叶斯Bootstrap方法
    - 近似贝叶斯Bootstrap方法
  - 基于模型的填补方法
  - 哑变量方法
- 数据的标准化
  - Z-Score
  - 0-1标准化
  - 小数定标标准化
  - Logistic标准化
- 数据的编码
  - 数字编码
  - one-hot编码
  - 哑变量编码
- 数据的离散化
  - 无监督的离散化方法
    - 等距离散化
    - 等频离散化
    - 基于聚类分析的离散化
  - 有监督的离散化方法
    - 基于信息增益
    - 基于卡方
- 特征的选择与降维
  - 降维的分类
    - 线性降维方法
      - **主成分分析**（PCA）
      - 线性判别分析
    - 非线性降维方法
      - 多维尺度变换
      - 局部线性嵌入

# 分类与回归模型

分类目标属性y是离散的，回归目标属性y是连续地。

## 决策树

- CLS-离散离散
- ID3
  - **信息增益度**
    - **信息熵**
      - 信息熵不纯度最大，对不纯度的惩罚最强
    - **Gini指数**
    - 误分率
  - 特点
    - 内部节点表示一个特征，叶节点表示一个类
    - 倾向于分裂成很多的小节点（节点的样本数较小），容易造成过度拟合
- C4.5
  - 采用**信息增益率**，避免分裂成过多的子节点

## K近邻

- **欧氏距离**
- **曼哈顿距离**
- 马氏距离
- 余弦距离
- 特点
  - 对异常数据不敏感，具有较好的抗噪性
  - K近邻算法的计算效率不高
  - 当训练集较小的时候，K近邻算法易导致过度拟合

## 线性回归

- 一元线性回归模型
- 多元线性回归模型
  - **参数估计：最小二乘估计**

## 非线性回归

- **多项式回归**
  - 线性回归的过拟合问题
    - 减少特征数量
    - 正则化-保留所有特征，但是减少参数𝜔 的值
      - 偏好学习更小的权值
      - 折中考虑小权值和最小化原来代价函数的方法
    - 正则化方法
      - L1正则化-Lasso回归
        - L1正则化可以防止过拟合；同时会产生稀疏权值矩阵，即产生一个稀疏模型，可以用于特征选择
      - L2正则化的模型叫做Ridge回归（岭回归）
        - L2正则化可以防止模型过拟合

## 支持向量机SVM

核函数Kernel的作用就是隐含着一个从低维空间到高维空间的映射，而这个映射可以把低维空间中线性不可分的两类点变成线性可分的，其目的与多项式特征中升维是一样的道理。

SVM是如何最优化选择决策边界，提升泛化能力：最大化d，Hard Margin SVM的改进，具有容错能力的Soft Margin SVM。

## 朴素贝叶斯

- 0概率处理-拉普拉斯平滑修正
- 特征是连续变量
  - 特征离散化
  - 高斯模型-假定连续特征服从正态分布，使用正态分布对条件参数进行求解。
- 特征是离散的且有多个取值-多项式模型

## 关联规则挖掘

- 支持度-A和B同时出现的次数
- 置信度-A和B同时出现占B的次数
- 关联规则挖掘
  - 第一步：需要找出满足最小支持度阈值的项集，即**频繁项集**；
  - 第二步：根据最小置信度阈值，从频繁项集中生成强关联规则。
- Apriori性质：如果一个项集A是频繁项集，那么它的非空子集B也是频繁项集。
- Apriori算法：剪枝
  - FP-Growth 算法

# 聚类模型

## 划分聚类K-means

- 选择K个点作为初始质心
- Repeat：
  - 将每个点指派到最近的
    质心形成K个簇
  - 重新计算每个簇的质心
- 直到质心不发生变化

# 后记

选择题：20*2分，不定项选择，有很多出现在酷客数据学习网上的原题，一定要做一遍原题

大题：3*15必做大题，1道选做大题，都做有加分。

必做大题为：

1. 数据的预处理，计算中位数、中列数、标准化这些的；
2. PageRank算法；
3. K均值聚类；

选做大题为：

1. 线性回归
2. 关联规则挖掘
